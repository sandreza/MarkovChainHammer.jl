var documenterSearchIndex = {"docs":
[{"location":"API/Uncertainty Quantification/bayesian_empirical_generator/#sec:bayesian_empirical","page":"Bayesian Empirical Generator","title":"Bayesian Empirical Generator","text":"","category":"section"},{"location":"API/Uncertainty Quantification/bayesian_empirical_generator/","page":"Bayesian Empirical Generator","title":"Bayesian Empirical Generator","text":"In this section we will show how to utilise the Bayesian empirical generator to estimate the uncertainty of the entries in the empirical generator from finite data. We we will do so by generating a Markov chain from a generator matrix. First let's load a few packages and functions that we've become familiar with over the last few sections.","category":"page"},{"location":"API/Uncertainty Quantification/bayesian_empirical_generator/","page":"Bayesian Empirical Generator","title":"Bayesian Empirical Generator","text":"using Random, MarkovChainHammer, Statistics\nusing MarkovChainHammer.TransitionMatrix: generator\nusing MarkovChainHammer.Trajectory: generate\nRandom.seed!(1234)","category":"page"},{"location":"API/Uncertainty Quantification/bayesian_empirical_generator/","page":"Bayesian Empirical Generator","title":"Bayesian Empirical Generator","text":"Observe the use of the Random package to set the seed for the random number generator. This is important for reproducibility of the results. A seed should only be defined once at the beginning of a script. ","category":"page"},{"location":"API/Uncertainty Quantification/bayesian_empirical_generator/","page":"Bayesian Empirical Generator","title":"Bayesian Empirical Generator","text":"We will now create a generator matrix Q and generate a markov process.","category":"page"},{"location":"API/Uncertainty Quantification/bayesian_empirical_generator/","page":"Bayesian Empirical Generator","title":"Bayesian Empirical Generator","text":"Q = [-1.0 4/3 2; 1/4 -2.0 1; 3/4 2/3 -3.0]\ndt = 0.01\nmarkov_chain = generate(Q, 10000; dt = dt)'","category":"page"},{"location":"API/Uncertainty Quantification/bayesian_empirical_generator/","page":"Bayesian Empirical Generator","title":"Bayesian Empirical Generator","text":"We first construct the empirical generator as before to serve as a comparison point for the Bayesian empirical generator which will come later.","category":"page"},{"location":"API/Uncertainty Quantification/bayesian_empirical_generator/","page":"Bayesian Empirical Generator","title":"Bayesian Empirical Generator","text":"Qempirical = generator(markov_chain; dt = dt)","category":"page"},{"location":"API/Uncertainty Quantification/bayesian_empirical_generator/","page":"Bayesian Empirical Generator","title":"Bayesian Empirical Generator","text":"We are now ready to introduce the Bayesian Generator matrix. We first load in the BayesianMatrix submodule.","category":"page"},{"location":"API/Uncertainty Quantification/bayesian_empirical_generator/","page":"Bayesian Empirical Generator","title":"Bayesian Empirical Generator","text":"using MarkovChainHammer.BayesianMatrix","category":"page"},{"location":"API/Uncertainty Quantification/bayesian_empirical_generator/","page":"Bayesian Empirical Generator","title":"Bayesian Empirical Generator","text":"This submodule naturally exports a number of structs and functions. We can see the names of these functions by typing the following: ","category":"page"},{"location":"API/Uncertainty Quantification/bayesian_empirical_generator/","page":"Bayesian Empirical Generator","title":"Bayesian Empirical Generator","text":"names(MarkovChainHammer.BayesianMatrix)","category":"page"},{"location":"API/Uncertainty Quantification/bayesian_empirical_generator/","page":"Bayesian Empirical Generator","title":"Bayesian Empirical Generator","text":"In particular a BayesianGenerator object is exported. We use the BayesianGenerator just like a normal generator in order to construct a BayesianGenerator","category":"page"},{"location":"API/Uncertainty Quantification/bayesian_empirical_generator/","page":"Bayesian Empirical Generator","title":"Bayesian Empirical Generator","text":"Q_bayes = BayesianGenerator(markov_chain; dt = dt)","category":"page"},{"location":"API/Uncertainty Quantification/bayesian_empirical_generator/","page":"Bayesian Empirical Generator","title":"Bayesian Empirical Generator","text":"This is no longer a regular matrix, but rather a random matrix whose entries are given by a probability distribution consistent with finite sampling from a markov process. In the present context (this will change later when we discuss prior distributions) the mean of the Bayesian matrix reproduces the same matrix as the empirically obtained matrix, as we can check","category":"page"},{"location":"API/Uncertainty Quantification/bayesian_empirical_generator/","page":"Bayesian Empirical Generator","title":"Bayesian Empirical Generator","text":"mean(Q_bayes) - Qempirical","category":"page"},{"location":"API/Uncertainty Quantification/bayesian_empirical_generator/","page":"Bayesian Empirical Generator","title":"Bayesian Empirical Generator","text":"However, we have more than just a mean value for the Bayesian matrix, we also have variances ","category":"page"},{"location":"API/Uncertainty Quantification/bayesian_empirical_generator/","page":"Bayesian Empirical Generator","title":"Bayesian Empirical Generator","text":"var(Q_bayes)","category":"page"},{"location":"API/Uncertainty Quantification/bayesian_empirical_generator/","page":"Bayesian Empirical Generator","title":"Bayesian Empirical Generator","text":"and standard deviations","category":"page"},{"location":"API/Uncertainty Quantification/bayesian_empirical_generator/","page":"Bayesian Empirical Generator","title":"Bayesian Empirical Generator","text":"std(Q_bayes)","category":"page"},{"location":"API/Uncertainty Quantification/bayesian_empirical_generator/","page":"Bayesian Empirical Generator","title":"Bayesian Empirical Generator","text":"We can check that the mean falls within two standard deviations of the true empirical estimate with high probability","category":"page"},{"location":"API/Uncertainty Quantification/bayesian_empirical_generator/","page":"Bayesian Empirical Generator","title":"Bayesian Empirical Generator","text":"abs.(mean(Q_bayes) - Q) .<  2 * std(Q_bayes)","category":"page"},{"location":"Modules/trajectory/#sec:trajectory","page":"Trajectory","title":"Trajectory","text":"","category":"section"},{"location":"Modules/trajectory/","page":"Trajectory","title":"Trajectory","text":"This module generates Markov chains from a transfer operator. The most useful function is the generate function. The generate function takes a transfer operator and a number of steps and returns a Markov chain. ","category":"page"},{"location":"function_index/#sec:function_index","page":"Function Index","title":"List of functions in MarkovChainHammer","text":"","category":"section"},{"location":"function_index/","page":"Function Index","title":"Function Index","text":"Modules = [ MarkovChainHammer.TransitionMatrix, MarkovChainHammer.BayesianMatrix, MarkovChainHammer.Trajectory, MarkovChainHammer.Clustering, MarkovChainHammer.Utils]","category":"page"},{"location":"function_index/#MarkovChainHammer.TransitionMatrix.decorrelation_times-Tuple{Any}","page":"Function Index","title":"MarkovChainHammer.TransitionMatrix.decorrelation_times","text":"decorrelation_times(Q)\n\nDescription\n\nCalculate the decorrelation times of a generator matrix.\n\nArguments\n\nQ::Matrix: The generator matrix or transition matrix.\n\nReturns\n\ndecorrelation_times::Vector: The decorrelation times of the generator matrix.\n\n\n\n\n\n","category":"method"},{"location":"function_index/#MarkovChainHammer.TransitionMatrix.entropy-Tuple{Any}","page":"Function Index","title":"MarkovChainHammer.TransitionMatrix.entropy","text":"entropy(p)\n\nDescription\n\nCalculate the entropy of a probability distribution. Normalized by the entropy of the uniform distribution.\n\nArguments\n\np::Vector: The probability distribution.\n\nReturns\n\nentropy_value::Real: The entropy of the probability distribution.\n\n\n\n\n\n","category":"method"},{"location":"function_index/#MarkovChainHammer.TransitionMatrix.generator-Tuple{Any}","page":"Function Index","title":"MarkovChainHammer.TransitionMatrix.generator","text":"generator(markov_chain; dt=1)\n\nDescription\n\nCalculate the generator matrix from a markov chain.\n\nArguments\n\nmarkov_chain::AbstractVector: A vector of integers representing the state of a markov chain at each time step.\ndt::Real: The time step between each state.\n\nReturns\n\ngenerator_matrix::Matrix: The generator matrix of the markov chain.\n\n\n\n\n\n","category":"method"},{"location":"function_index/#MarkovChainHammer.TransitionMatrix.holding_times-Tuple{Any, Any}","page":"Function Index","title":"MarkovChainHammer.TransitionMatrix.holding_times","text":"holding_times(markov_chain, number_of_states; dt=1)\n\nDescription\n\nCalculate the holding times of a markov chain.\n\nArguments\n\nmarkov_chain::AbstractVector: A vector of integers representing the state of a markov chain at each time step.\nnumber_of_states::Integer: The number of states in the markov chain.\ndt::Real: The time step of the markov chain.\n\nReturns\n\nholding_times::Vector{Vector{Real}}: A vector of vectors of holding times for each state.\n\n\n\n\n\n","category":"method"},{"location":"function_index/#MarkovChainHammer.TransitionMatrix.koopman_modes-Tuple{Any}","page":"Function Index","title":"MarkovChainHammer.TransitionMatrix.koopman_modes","text":"koopman_modes(Q)\n\nDescription\n\nCalculate the koopman modes of a generator matrix.\n\nArguments\n\nQ::Matrix: The generator matrix or transition matrix.\n\nReturns\n\nV⁻¹::Matrix: The koopman modes of the generator matrix. Each row is a koopman mode\n\n\n\n\n\n","category":"method"},{"location":"function_index/#MarkovChainHammer.TransitionMatrix.perron_frobenius-Tuple{Any}","page":"Function Index","title":"MarkovChainHammer.TransitionMatrix.perron_frobenius","text":"perron_frobenius(markov_chain; step = 1)\n\nDescription\n\nCalculate the perron-frobenius matrix from a markov chain.\n\nArguments\n\nmarkov_chain::AbstractVector: A vector of integers representing the state of a markov chain at each time step.\n\nKeyword Arguments\n\nstep::Integer=1: The step size of the constructed operator.\n\nReturns\n\nperron_frobenius_matrix::Matrix: The perron-frobenius matrix of the markov chain.\n\n\n\n\n\n","category":"method"},{"location":"function_index/#MarkovChainHammer.TransitionMatrix.steady_state-Tuple{Any}","page":"Function Index","title":"MarkovChainHammer.TransitionMatrix.steady_state","text":"steady_state(Q)\n\nDescription\n\nCalculate the steady state of a generator matrix.\n\nArguments\n\nQ::Matrix: The generator matrix or transition matrix.\n\nReturns\n\np::Vector: The steady state of the generator matrix.\n\n\n\n\n\n","category":"method"},{"location":"function_index/#MarkovChainHammer.TransitionMatrix.symmetric_generator-Tuple{Any, Any}","page":"Function Index","title":"MarkovChainHammer.TransitionMatrix.symmetric_generator","text":"symmetric_generator(markov_chain, symmetries; dt=1)\n\nDescription\n\nCalculate the generator matrix from a markov chain with symmetries.\n\nArguments\n\nmarkov_chain::AbstractVector: A vector of integers representing the state of a markov chain at each time step.\nsymmetries::AbstractVector: A vector of functions that are symmetries of the markov chain.\ndt::Real: The time step between each state.\n\nReturns\n\ngenerator_matrix::Matrix: The generator matrix of the markov chain.\n\n\n\n\n\n","category":"method"},{"location":"function_index/#MarkovChainHammer.TransitionMatrix.symmetric_perron_frobenius-Tuple{Any, Any}","page":"Function Index","title":"MarkovChainHammer.TransitionMatrix.symmetric_perron_frobenius","text":"symmetric_perron_frobenius(markov_chain, symmetries)\n\nDescription\n\nCalculate the perron-frobenius matrix from a markov chain with symmetries.\n\nArguments\n\nmarkov_chain::AbstractVector: A vector of integers representing the state of a markov chain at each time step.\nsymmetries::AbstractVector: A vector of functions that are symmetries of the markov chain.\n\nReturns\n\nperron_frobenius_matrix::Matrix: The perron-frobenius matrix of the markov chain.\n\n\n\n\n\n","category":"method"},{"location":"function_index/#MarkovChainHammer.BayesianMatrix.BayesianGenerator-Tuple{Any, MarkovChainHammer.BayesianMatrix.GeneratorParameterDistributions}","page":"Function Index","title":"MarkovChainHammer.BayesianMatrix.BayesianGenerator","text":"BayesianGenerator(data, prior::GeneratorParameterDistributions; dt=1)\n\nConstruct a BayesianGenerator object from data and a prior distribution.\n\nArguments\n\ndata::Vector{Int}: The data to construct the BayesianGenerator object from.\nprior::GeneratorParameterDistributions: The prior distribution for the BayesianGenerator object.\n\nKeyword Arguments\n\ndt::Number=1: The time step between each data point.\n\nReturns\n\nBayesianGenerator: A BayesianGenerator object constructed from the data and the prior distribution. Contains the posterior distributions for the rates and exit probabilities, as well as the predictive distributions for the holding times and exit counts.\n\n\n\n\n\n","category":"method"},{"location":"function_index/#MarkovChainHammer.BayesianMatrix.BayesianGenerator-Tuple{Vector{Vector{Int64}}, MarkovChainHammer.BayesianMatrix.GeneratorParameterDistributions}","page":"Function Index","title":"MarkovChainHammer.BayesianMatrix.BayesianGenerator","text":"BayesianGenerator(data::Vector{Vector{Int64}}, prior::GeneratorParameterDistributions; dt=1)\n\nThe ensemble version of the BayesianGenerator constructor. Here the data is a vector of vectors of integers, where each vector of integers is a single ensemble member trajectory.\n\n# Arguments\n- `data::Vector{Vector{Int64}}`: The data to construct the BayesianGenerator object from.\n- `prior::GeneratorParameterDistributions`: The prior distribution for the BayesianGenerator object.\n\n# Keyword Arguments\n- `dt::Number=1`: The time step between each data point.\n\n# Returns\n- `BayesianGenerator`: A BayesianGenerator object constructed from the data and the prior distribution. Contains the posterior distributions for the rates and exit probabilities, as well as the predictive distributions for the holding times and exit counts.\n\n\n\n\n\n","category":"method"},{"location":"function_index/#MarkovChainHammer.BayesianMatrix.GeneratorParameterDistributions-Tuple{Int64}","page":"Function Index","title":"MarkovChainHammer.BayesianMatrix.GeneratorParameterDistributions","text":"GeneratorParameterDistributions(number_of_states::Int; α=1, β=1, αs=ones(number_of_states - 1))\n\nConstruct a GeneratorParameterDistributions object with Gamma(α, 1/β) prior distributions for the rates and Dirichlet(αs) prior distributions for the exit probabilities. Each state has the same probability distribution This is useful for construction prior distributions quickly. The underlying assumption for default rates is that the units of time are 1, and thus the rates are all by default 1. Futhermore the mean probability of each state is  1/(numberofstates-1)\n\nThe reason why the αs is of length(numberofstates - 1) is because they are exit probabilities, and hence the probability of returning to the same state is 0. The index ordering for the exit probability of state i, is [1:i-1..., i+1:numberofstates...].  For example, if numberofstates = 3, then the index ordering for state 1 is indices = [2, 3], i.e., indices[1] = 2 and indices[2] = 3, meaning, the first index corresponds to exiting through state 2 and the second index corresponds to exiting through state 3. The index ordering for state 2 is indices = [1, 3], i.e., indices[1] = 1 and indices[2] = 3, meaning, the first index corresponds to exiting through state 1 and the second index corresponds to exiting through state 3. The index ordering for state 3 is indices = [1, 2], i.e., indices[1] = 1 and indices[2] = 2, meaning, the first index corresponds to exiting through state 1 and the second index corresponds to exiting through state 2.\n\nArguments\n\nnumber_of_states::Int: The number of states in the Markov chain.\n\nKeyword Arguments\n\nα::Number=2: The shape parameter for the Gamma prior distribution for the rates.\nβ::Number=2: The rate parameter for the Gamma prior distribution for the rates.\nαs::Vector{Number}=ones(number_of_states - 1): The concentration parameters for the Dirichlet prior distribution for the exit probabilities.\n\nReturns\n\nGeneratorParameterDistributions: A GeneratorParameterDistributions object with Gamma(α, 1/β) prior distributions for the rates and Dirichlet(αs) prior distributions for the exit probabilities.\n\nNote on the Gamma prior distribution (from https://en.wikipedia.org/wiki/Gamma_distribution)\n\nThe Gamma distribution is a conjugate prior distribution for the exponential family distribution of the rates. The Gamma distribution is parameterized by the shape parameter α and the rate parameter β. The mean of the Gamma distribution is α/β and the variance is α/β^2.\n\nNote on the Dirichlet prior distribution (from https://en.wikipedia.org/wiki/Dirichlet_distribution)\n\nThe Dirichlet prior distribution is a conjugate prior distribution for the multinomial distribution of the exit probabilities. The Dirichlet prior distribution is parameterized by the concentration parameters αs.  The mean of the Dirichlet distribution is E[X⃗] = αs/sum(αs)  The covariance is CoVar[X⃗ ⊗ X⃗] = Diagonal(α̃) - α̃ ⊗ α̃ / (α₀ + 1) where α̃ = αs / α₀  and α₀ = sum(αs). The variance Var(Xᵢ) = α̃ᵢ(1-α̃ᵢ) / (α₀ + 1) where α₀ = sum(αs).\n\n\n\n\n\n","category":"method"},{"location":"function_index/#MarkovChainHammer.Trajectory.ContinuousTimeEmpiricalProcess-Tuple{Any}","page":"Function Index","title":"MarkovChainHammer.Trajectory.ContinuousTimeEmpiricalProcess","text":"ContinuousTimeEmpiricalProcess(markovchain; numberofstates=length(union(markovchain)))\n\nConstruct a continuous time empirical process from a discrete time Markov chain. The holding times are taken from the empirical distribution and the transition probabilities from the empirical transition probabilities\n\nArguments\n\nmarkov_chain::Vector{Int}: The discrete time Markov chain to construct the continuous time empirical process from.\n\nKeyword Arguments\n\nnumber_of_states::Int=length(union(markov_chain)): The number of states in the Markov chain.\n\nReturns\n\nContinuousTimeEmpiricalProcess: A continuous time empirical process constructed from the discrete time Markov chain.\n\n\n\n\n\n","category":"method"},{"location":"function_index/#MarkovChainHammer.Trajectory.generate-NTuple{4, Any}","page":"Function Index","title":"MarkovChainHammer.Trajectory.generate","text":"generate(Q, n; dt=1, initial_condition=rand(1:size(Q)[1]))\n\nGenerate a Markov chain of length n with transition matrix Q and time step dt.\n\nArguments\n\nQ::AbstractMatrix: The transition matrix or generator of the Markov chain.\nn::Int: The length of the Markov chain.\ndt::Real=1: The time step of the Markov chain.\ninitial_condition::Int=rand(1:size(Q)[1]): The initial condition of the Markov chain.\n\nKeyword Arguments\n\nprogress::Bool=false: Whether to show a progress bar.\n\nReturns\n\nVector{Int}: A Markov chain of length n generated by transition matrix Q and time step dt.\n\n\n\n\n\n","category":"method"},{"location":"function_index/#MarkovChainHammer.Trajectory.generate-Tuple{MarkovChainHammer.Trajectory.ContinuousTimeEmpiricalProcess, Any, Any}","page":"Function Index","title":"MarkovChainHammer.Trajectory.generate","text":"generate(process::ContinuousTimeEmpiricalProcess, n; initial_condition=rand(1:size(process.cumulative_distribution)[1]))\n\nGenerate a Markov chain of length n with continuous time empirical process process.\n\nArguments\n\nprocess::ContinuousTimeEmpiricalProcess: The continuous time empirical process to generate a Markov chain from.\nn::Int: Number of jumps to generate. i.e. lower bound to length of markov chain \ninitial_condition::Int=rand(1:size(process.cumulative_distribution)[1]): The initial condition of the Markov chain.\n\nKeyword Arguments\n\nprogress::Bool=false: Whether to show a progress bar.\n\nReturns\n\nVector{Int}: A Markov chain of generated by a continuous time empirical process.\n\n\n\n\n\n","category":"method"},{"location":"function_index/#MarkovChainHammer.Clustering.leicht_newman-Tuple{Any}","page":"Function Index","title":"MarkovChainHammer.Clustering.leicht_newman","text":"leicht_newman(A; modularity_type = :giorgini)\n\nDescription\n\nCompute the communities of a graph using the Leicht Newman algorithm.\n\nArguments\n\nA::AbstractArray: Adjacency matrix of the graph.\n\nKeyword Arguments\n\nmodularity_type::Symbol: Type of modularity matrix to use. Can be :giorgini, :modularity, :generator_fine, or :generator_coarse. Defaults to :modularity.\n\nReturns\n\nAbstractArray: Array of communities.\n\n\n\n\n\n","category":"method"},{"location":"function_index/#MarkovChainHammer.Utils.autocovariance-Tuple{Any, LinearAlgebra.Eigen, Any}","page":"Function Index","title":"MarkovChainHammer.Utils.autocovariance","text":"autocovariance(g⃗, Q::Eigen, timelist; progress=false)\n\nCalculate the autocovariance of observable g⃗ with generator matrix Q and times at timelist. \n\nArguments\n\ng⃗::AbstractVector: observable\nQ::Eigen: eigenvalue decomposition of generator matrix\ntimelist::AbstractVector: times at which to calculate autocovariance\n\nKeyword Arguments\n\nprogress::Bool=false: show a progress bar\n\nReturns\n\nautocov::Vector: autocovariance of observable g⃗ with generator matrix Q and times at timelist\n\n\n\n\n\n","category":"method"},{"location":"function_index/#MarkovChainHammer.Utils.autocovariance-Tuple{Any, Vector{Matrix{Float64}}, Int64}","page":"Function Index","title":"MarkovChainHammer.Utils.autocovariance","text":"autocovariance(g⃗, Ps::Vector{Matrix{Float64}}, steps::Int; progress = false)\n\nCalculate the autocovariance of observable g⃗ with transition matrices Ps and number of steps.\n\nArguments\n\ng⃗::AbstractVector: observable\nPs::Vector{Matrix{Float64}}: transition matrices\nsteps::Int: number of steps\n\nKeyword Arguments\n\nprogress::Bool=false: show a progress bar\n\nReturns\n\nautocov::Vector: autocovariance of observable g⃗ with transition matrices Ps and number of steps\n\n\n\n\n\n","category":"method"},{"location":"function_index/#MarkovChainHammer.Utils.autocovariance-Tuple{Any}","page":"Function Index","title":"MarkovChainHammer.Utils.autocovariance","text":"autocovariance(x; timesteps=length(x), progress = false)\n\nCalculate the autocovariance of a timeseries x with timesteps lags.\n\nArguments\n\nx::AbstractVector: timeseries\n\nKeyword Arguments\n\ntimesteps::Int: number of lags\nprogress::Bool: show a progress bar\n\nReturns\n\nautocov::Vector: autocovariance of x with timesteps lags\n\n\n\n\n\n","category":"method"},{"location":"function_index/#MarkovChainHammer.Utils.histogram-Tuple{Any}","page":"Function Index","title":"MarkovChainHammer.Utils.histogram","text":"histogram(array, bins=minimum([100, length(array)]), normalization=:uniform, custom_range=false)\n\nDescription\n\nCompute the histogram of an array. Useful for barplot in GLMakie.\n\nArguments\n\narray::AbstractArray: Array to compute the histogram of.\nbins::Integer: Number of bins to use.\nnormalization::AbstractArray: Normalization to use. If :uniform, then the normalization is uniform.\ncustom_range::Tuple: Custom range to use. If false, then the range is computed from the data.\n\nReturns\n\nTuple{AbstractArray, AbstractArray}: Tuple of the bin centers and the histogram values.\n\n\n\n\n\n","category":"method"},{"location":"Modules/clustering/#sec:clustering","page":"Clustering","title":"Clustering","text":"","category":"section"},{"location":"Modules/clustering/","page":"Clustering","title":"Clustering","text":"In a community detection problem the goal is to find communities from network information. In this case we don't have an adjacency matrix, but rather a transfer operator. Thus connections between vertices are not just given by 0's and 1's, but rather by a continuum of numbers in between.","category":"page"},{"location":"API/Uncertainty Quantification/sampling/#sec:generator_sampling","page":"Sampling from the Bayesian Generator","title":"Sampling from the Bayesian Generator","text":"","category":"section"},{"location":"API/Uncertainty Quantification/sampling/","page":"Sampling from the Bayesian Generator","title":"Sampling from the Bayesian Generator","text":"We now discuss how to use the BayesianGenerator to propogate uncertainty. ","category":"page"},{"location":"API/Uncertainty Quantification/sampling/","page":"Sampling from the Bayesian Generator","title":"Sampling from the Bayesian Generator","text":"As usual we start by bringing in packages","category":"page"},{"location":"API/Uncertainty Quantification/sampling/","page":"Sampling from the Bayesian Generator","title":"Sampling from the Bayesian Generator","text":"using Random, MarkovChainHammer, Statistics, LinearAlgebra\nusing MarkovChainHammer.BayesianMatrix\nusing MarkovChainHammer.TransitionMatrix: generator\nusing MarkovChainHammer.Trajectory: generate\nRandom.seed!(1234)","category":"page"},{"location":"API/Uncertainty Quantification/sampling/","page":"Sampling from the Bayesian Generator","title":"Sampling from the Bayesian Generator","text":"and starting off with a generator that generates a stochastic process","category":"page"},{"location":"API/Uncertainty Quantification/sampling/","page":"Sampling from the Bayesian Generator","title":"Sampling from the Bayesian Generator","text":"Q = [-1.0 4/3 2; 1/4 -2.0 1; 3/4 2/3 -3.0]\ndt = 0.01\nmarkov_chain = generate(Q, 10000; dt = dt)'","category":"page"},{"location":"API/Uncertainty Quantification/sampling/","page":"Sampling from the Bayesian Generator","title":"Sampling from the Bayesian Generator","text":"We construct the BayesianGenerator object from a prior distribution","category":"page"},{"location":"API/Uncertainty Quantification/sampling/","page":"Sampling from the Bayesian Generator","title":"Sampling from the Bayesian Generator","text":"number_of_states = 3\nprior = GeneratorParameterDistributions(number_of_states)\nQ_bayes = BayesianGenerator(markov_chain, prior; dt = dt)","category":"page"},{"location":"API/Uncertainty Quantification/sampling/","page":"Sampling from the Bayesian Generator","title":"Sampling from the Bayesian Generator","text":"We can now sample from the BayesianGenerator object which gives a random matrix drawn from the posterior distribution","category":"page"},{"location":"API/Uncertainty Quantification/sampling/","page":"Sampling from the Bayesian Generator","title":"Sampling from the Bayesian Generator","text":"rand(Q_bayes)","category":"page"},{"location":"API/Uncertainty Quantification/sampling/","page":"Sampling from the Bayesian Generator","title":"Sampling from the Bayesian Generator","text":"If we call the rand function again we get a different realization","category":"page"},{"location":"API/Uncertainty Quantification/sampling/","page":"Sampling from the Bayesian Generator","title":"Sampling from the Bayesian Generator","text":"rand(Q_bayes)","category":"page"},{"location":"API/Uncertainty Quantification/sampling/","page":"Sampling from the Bayesian Generator","title":"Sampling from the Bayesian Generator","text":"We can call the rand function with an additional integer argument to get a list of realizations","category":"page"},{"location":"API/Uncertainty Quantification/sampling/","page":"Sampling from the Bayesian Generator","title":"Sampling from the Bayesian Generator","text":"number_of_samples = 100\nQ_bayes_list = rand(Q_bayes, number_of_samples)","category":"page"},{"location":"API/Uncertainty Quantification/sampling/","page":"Sampling from the Bayesian Generator","title":"Sampling from the Bayesian Generator","text":"from whence we can compute the sample mean and compare to the analytic mean","category":"page"},{"location":"API/Uncertainty Quantification/sampling/","page":"Sampling from the Bayesian Generator","title":"Sampling from the Bayesian Generator","text":"mean(Q_bayes_list) - mean(Q_bayes)","category":"page"},{"location":"API/Uncertainty Quantification/sampling/","page":"Sampling from the Bayesian Generator","title":"Sampling from the Bayesian Generator","text":"and similarly for the sample variance","category":"page"},{"location":"API/Uncertainty Quantification/sampling/","page":"Sampling from the Bayesian Generator","title":"Sampling from the Bayesian Generator","text":"var(Q_bayes_list) - var(Q_bayes)","category":"page"},{"location":"API/Continuous Time/empirical_generator/#sec:empirical_generator","page":"Empirical Generator","title":"Empirical Generator","text":"","category":"section"},{"location":"API/Continuous Time/empirical_generator/","page":"Empirical Generator","title":"Empirical Generator","text":"In this section, we will see how to construct a generator from data. This is useful when we don't know the underlying generator. There is an inherent limitation in constructing generators that wasn't present when constructing the transfer operator: The data comes at a fixed timescale, thus the generator will only be known up to the timescales present in the timeseries. Nonetheless it is possible to construct a generator from the timeseries under a few assumptions. ","category":"page"},{"location":"API/Continuous Time/empirical_generator/","page":"Empirical Generator","title":"Empirical Generator","text":"For example, suppose that we have the Markov chain with three states","category":"page"},{"location":"API/Continuous Time/empirical_generator/","page":"Empirical Generator","title":"Empirical Generator","text":"markov_chain = [1 1 2 2 2 1 3 1 1 2 2]","category":"page"},{"location":"API/Continuous Time/empirical_generator/","page":"Empirical Generator","title":"Empirical Generator","text":"and we want to estimate the transfer operator from this data. We can do this by using the function generator which is imported from the MarkovChainHammer.TransitionMatrix module. This function takes a Markov chain as input and returns the empirical transition matrix of the Markov chain. We assume that the time intervals are uniform in time with timestep dt = 1","category":"page"},{"location":"API/Continuous Time/empirical_generator/","page":"Empirical Generator","title":"Empirical Generator","text":"using MarkovChainHammer.TransitionMatrix: generator\ndt = 1.0\nQ = generator(markov_chain; dt = dt)\nQ","category":"page"},{"location":"API/Continuous Time/empirical_generator/","page":"Empirical Generator","title":"Empirical Generator","text":"This matrix is constructed by counting the amount of time spent in a state to construct the diagonal entries of the matrix, i.e., the holding times. We can manually import the holding times to understand the construction of the Q matrix, from the MarkovChainHammer.TransitionMatrix function holding_times","category":"page"},{"location":"API/Continuous Time/empirical_generator/","page":"Empirical Generator","title":"Empirical Generator","text":"using MarkovChainHammer.TransitionMatrix: holding_times\nstate_holding_times = holding_times(markov_chain, 3; dt = dt)","category":"page"},{"location":"API/Continuous Time/empirical_generator/","page":"Empirical Generator","title":"Empirical Generator","text":"The first argument to the function is the markovchain, the second argument is the total number of states, and the keyword argument is the time step size associated with the entries of the markovchain.","category":"page"},{"location":"API/Continuous Time/empirical_generator/","page":"Empirical Generator","title":"Empirical Generator","text":"We see, from the markov chain, that state 1 spends 2 time units in state 1, followed by 1 time unit, then follow by 2 time units. State 2 spends 3 time units repeating itself, then two time units. And lastly, state 3 is only observed once for one time unit.","category":"page"},{"location":"API/Continuous Time/empirical_generator/","page":"Empirical Generator","title":"Empirical Generator","text":"The diagonals of the Q matrix are given by taking the average of the holding times, then taking the reciprocal. We can verify this manually by importing the mean function from the Statistics package.","category":"page"},{"location":"API/Continuous Time/empirical_generator/","page":"Empirical Generator","title":"Empirical Generator","text":"using Statistics\n1 ./ mean.(state_holding_times)","category":"page"},{"location":"API/Continuous Time/empirical_generator/","page":"Empirical Generator","title":"Empirical Generator","text":"We can verify the off diagonal terms as well. We just need to track the number of times that a given state was exited. For example, when leaving state 1 we observe 1 rightarrow 2, read as 1 transitions to 2, 1 rightarrow 3, and 1 rightarrow 2. Thus going from state state 1 to state 2 is twice as likely as going from state 1 to state 3 and the associated probabilities are 23 for transitioning from 1 to 2 and 13 for transitioning from 2 to 3. These two probabilities then get multiplied by the reciprocal empircal holding time for being in state 1, which in this case is 06 to yield the first column of the Q matrix ","category":"page"},{"location":"API/Continuous Time/empirical_generator/","page":"Empirical Generator","title":"Empirical Generator","text":"Q[:, 1]","category":"page"},{"location":"API/Continuous Time/empirical_generator/","page":"Empirical Generator","title":"Empirical Generator","text":"For the other two states we observe that we only see state 2 transitioning to state 1 and state 3 only ever transitions to state 1, thus the matrix entries are Q_32 = Q_23 = 0. The requirement that the columns must sum to zero then determines the other entries (or noticing that the probability of going to state 1 after having left state 2 is 1 and similarly for state 3).","category":"page"},{"location":"API/Continuous Time/empirical_generator/","page":"Empirical Generator","title":"Empirical Generator","text":"This brings us to our first warning about constructing the empirical generator. It is most meaningful when there is enough timeseries data to stay within a given state for more than one \"timestep\". ","category":"page"},{"location":"API/Continuous Time/empirical_generator/","page":"Empirical Generator","title":"Empirical Generator","text":"Our last comment is that changing dt amounts to rescaling the generator. That is to say, ","category":"page"},{"location":"API/Continuous Time/empirical_generator/","page":"Empirical Generator","title":"Empirical Generator","text":"Q1 = generator(markov_chain; dt = 1.0)\nQ2  = generator(markov_chain; dt = 2.0)\nQ1 - 2.0 * Q2 ","category":"page"},{"location":"API/Continuous Time/empirical_generator/","page":"Empirical Generator","title":"Empirical Generator","text":"As a last comment we mention that one can also construct the transfer operator, then take the matrix logarithm, and then divide by dt to get another estimate of the generator; however, the resulting matrix no longer has an \"infinitesimal\" probabilistic interpretation, as the following example shows","category":"page"},{"location":"API/Continuous Time/empirical_generator/","page":"Empirical Generator","title":"Empirical Generator","text":"using MarkovChainHammer.TransitionMatrix: perron_frobenius\ndt = 1.0\nℳ = perron_frobenius(markov_chain)\nlog(ℳ) / dt","category":"page"},{"location":"API/Continuous Time/empirical_generator/","page":"Empirical Generator","title":"Empirical Generator","text":"The columns still sum to zero, but the entries of the matrix no longer have an interpretation as holding times or probabilities. This example also shows why generators have a much more limited and special structure as compared to the transfer operator. The requirement that one generates probabilities over infinitesimal steps imposes severe restrictions. We may lift these restrictions if we are willing to give up computing an infinitesimal generator and live with generators that are applicable only over a finite timescale. This fact reflects a well-known theorem in numerical analysis that positivity preserving linear operators are inherently lower-order. ","category":"page"},{"location":"API/Continuous Time/empirical_generator/","page":"Empirical Generator","title":"Empirical Generator","text":"An alternative way to construct the generator from the perron-frobenius operator is to take the difference between the identity matrix and the perron-frobenius operator and then divide by dt","category":"page"},{"location":"API/Continuous Time/empirical_generator/","page":"Empirical Generator","title":"Empirical Generator","text":"using LinearAlgebra\ndt = 1.0\nQ = (ℳ - I) / dt","category":"page"},{"location":"API/Continuous Time/empirical_generator/","page":"Empirical Generator","title":"Empirical Generator","text":"where we had to use the LinearAlgebra package to import the identity matrix. This calculation makes use of the relation that the generator is the infinitesimal generator of the perron-frobenius operator","category":"page"},{"location":"API/Continuous Time/empirical_generator/","page":"Empirical Generator","title":"Empirical Generator","text":"mathcalM = e^dt Q approx mathbbI + dt Q ","category":"page"},{"location":"API/Continuous Time/empirical_generator/","page":"Empirical Generator","title":"Empirical Generator","text":"This is only good if the timesteps are sufficiently small.","category":"page"},{"location":"API/Uncertainty Quantification/constructing_prior/#sec:constructing_priors","page":"Constructing Prior Distributions","title":"Constructing Prior Distributions","text":"","category":"section"},{"location":"API/Uncertainty Quantification/constructing_prior/","page":"Constructing Prior Distributions","title":"Constructing Prior Distributions","text":"In the previous section we saw how to use the BayesianGenerator object, similar to how we use the generator function. We now introduce the GeneratorParameterDistribution object in order to construct prior distributions for Bayesian inference. ","category":"page"},{"location":"API/Uncertainty Quantification/constructing_prior/","page":"Constructing Prior Distributions","title":"Constructing Prior Distributions","text":"We first load the necessary packages and functions","category":"page"},{"location":"API/Uncertainty Quantification/constructing_prior/","page":"Constructing Prior Distributions","title":"Constructing Prior Distributions","text":"using Random, MarkovChainHammer, Statistics\nusing MarkovChainHammer.BayesianMatrix\nusing MarkovChainHammer.TransitionMatrix: generator\nusing MarkovChainHammer.Trajectory: generate\nRandom.seed!(1234)","category":"page"},{"location":"API/Uncertainty Quantification/constructing_prior/","page":"Constructing Prior Distributions","title":"Constructing Prior Distributions","text":"We now introduce the GeneratorParameterDistribution object, which was exported from MarkovChainHammer.BayesianMatrix","category":"page"},{"location":"API/Uncertainty Quantification/constructing_prior/","page":"Constructing Prior Distributions","title":"Constructing Prior Distributions","text":"number_of_states = 3\nprior = GeneratorParameterDistributions(number_of_states)","category":"page"},{"location":"API/Uncertainty Quantification/constructing_prior/","page":"Constructing Prior Distributions","title":"Constructing Prior Distributions","text":"The prior distribution constitutes a guess for the entries of the matrix. We can check the mean of a random matrix generator from the prior distribution by calling the mean function on the prior","category":"page"},{"location":"API/Uncertainty Quantification/constructing_prior/","page":"Constructing Prior Distributions","title":"Constructing Prior Distributions","text":"mean(prior)","category":"page"},{"location":"API/Uncertainty Quantification/constructing_prior/","page":"Constructing Prior Distributions","title":"Constructing Prior Distributions","text":"From a generator we now create a markov chain","category":"page"},{"location":"API/Uncertainty Quantification/constructing_prior/","page":"Constructing Prior Distributions","title":"Constructing Prior Distributions","text":"Q = [-1.0 4/3 2; 1/4 -2.0 1; 3/4 2/3 -3.0]\ndt = 0.01\nmarkov_chain = generate(Q, 10000; dt = dt)'","category":"page"},{"location":"API/Uncertainty Quantification/constructing_prior/","page":"Constructing Prior Distributions","title":"Constructing Prior Distributions","text":"and now use our prior distribution along with the BayesianGenerator object","category":"page"},{"location":"API/Uncertainty Quantification/constructing_prior/","page":"Constructing Prior Distributions","title":"Constructing Prior Distributions","text":"Q_bayes = BayesianGenerator(markov_chain, prior; dt = dt)","category":"page"},{"location":"API/Uncertainty Quantification/constructing_prior/","page":"Constructing Prior Distributions","title":"Constructing Prior Distributions","text":"We see that we get a different answer than what we had before due to the presence of the prior distribution","category":"page"},{"location":"API/Uncertainty Quantification/constructing_prior/","page":"Constructing Prior Distributions","title":"Constructing Prior Distributions","text":"Q_bayes_uninformative_prior = BayesianGenerator(markov_chain; dt = dt)","category":"page"},{"location":"API/Uncertainty Quantification/constructing_prior/","page":"Constructing Prior Distributions","title":"Constructing Prior Distributions","text":"In particular we can check the mean ","category":"page"},{"location":"API/Uncertainty Quantification/constructing_prior/","page":"Constructing Prior Distributions","title":"Constructing Prior Distributions","text":"mean(Q_bayes) - mean(Q_bayes_uninformative_prior)","category":"page"},{"location":"Modules/module_overview/#sec:module_overview","page":"Overview","title":"Module Overview","text":"","category":"section"},{"location":"Modules/module_overview/","page":"Overview","title":"Overview","text":"In this section we will give a brief overview of the modules in this package. The modules are:","category":"page"},{"location":"Modules/module_overview/","page":"Overview","title":"Overview","text":"TransitionMatrix\nBayesianMatrix\nTrajectory\nClustering\nUtils","category":"page"},{"location":"Modules/utils/#sec:utilities","page":"Utils","title":"Utils","text":"","category":"section"},{"location":"Modules/utils/","page":"Utils","title":"Utils","text":"The most useful function is the histogram function which can be used alongside GLMakie to make barplots of the distribution of states in a Markov chain. ","category":"page"},{"location":"API/Continuous Time/convergence/#sec:generator_convergence","page":"Convergence of Generators","title":"Convergence of Generators","text":"","category":"section"},{"location":"API/Continuous Time/convergence/","page":"Convergence of Generators","title":"Convergence of Generators","text":"Convergence of a generator from data is more subtle than the convergence of a transfer operator from data due to the presence of time scales in the former.  For a fixed timestep size Delta t and infinite data we have convergence to the associated transfer operator. Thus we take the limit of Delta t rightarrow 0 afterwards to get convergence to the generator. ","category":"page"},{"location":"API/Continuous Time/convergence/","page":"Convergence of Generators","title":"Convergence of Generators","text":"Given the exact generator","category":"page"},{"location":"API/Continuous Time/convergence/","page":"Convergence of Generators","title":"Convergence of Generators","text":"Q_exact = [-1.0 2.0; 1.0 -2.0]\nQ_exact","category":"page"},{"location":"API/Continuous Time/convergence/","page":"Convergence of Generators","title":"Convergence of Generators","text":"We generate a Markov chains of increasing size at a fixed timestep dt and compute the empirical transition matrix. We then verify that the empirical transition matrix converges to the exact transition operator. Let us first generate a Markov chain of size 100.","category":"page"},{"location":"API/Continuous Time/convergence/","page":"Convergence of Generators","title":"Convergence of Generators","text":"using MarkovChainHammer.Trajectory: generate\nusing Random #hide\nRandom.seed!(1234) #hide\ndt = 1.0\nsteps = 100\nmarkov_chain = generate(Q_exact, steps; dt=dt); \nnothing; # hide","category":"page"},{"location":"API/Continuous Time/convergence/","page":"Convergence of Generators","title":"Convergence of Generators","text":"We now load the empirical operator constructors for both the generator and the transfer operator in order to seperately check for convergence. ","category":"page"},{"location":"API/Continuous Time/convergence/","page":"Convergence of Generators","title":"Convergence of Generators","text":"First let us construct the transfer operator","category":"page"},{"location":"API/Continuous Time/convergence/","page":"Convergence of Generators","title":"Convergence of Generators","text":"using MarkovChainHammer.TransitionMatrix: perron_frobenius\nℳ_empirical = perron_frobenius(markov_chain)","category":"page"},{"location":"API/Continuous Time/convergence/","page":"Convergence of Generators","title":"Convergence of Generators","text":"We see that the above matrix is close to the exact transfer operator","category":"page"},{"location":"API/Continuous Time/convergence/","page":"Convergence of Generators","title":"Convergence of Generators","text":"ℳ_exact = exp(Q_exact)","category":"page"},{"location":"API/Continuous Time/convergence/","page":"Convergence of Generators","title":"Convergence of Generators","text":"Now let us construct the generator","category":"page"},{"location":"API/Continuous Time/convergence/","page":"Convergence of Generators","title":"Convergence of Generators","text":"using MarkovChainHammer.TransitionMatrix: generator\nQ_empirical = generator(markov_chain; dt = dt)","category":"page"},{"location":"API/Continuous Time/convergence/","page":"Convergence of Generators","title":"Convergence of Generators","text":"We see that the above matrix is quite far from the exact generator, which leads to the question \"what happened?\". The resolution to this dilemma is to observe that timescales of the markov chain were too large as compared to the expected holding times of the exact generator, which are 1.0 for state 1 and 12 for state 2. If the chain is instead generated with smaller timesteps ","category":"page"},{"location":"API/Continuous Time/convergence/","page":"Convergence of Generators","title":"Convergence of Generators","text":"dt = 0.1\nmarkov_chain = generate(Q_exact, steps; dt=dt); \nQ_empirical = generator(markov_chain; dt = dt)","category":"page"},{"location":"API/Continuous Time/convergence/","page":"Convergence of Generators","title":"Convergence of Generators","text":"We can see that the estimate of the generator has improved. Note that we can also calculate the generator by taking the matrix logarithm and dividing by the timescale to get a similar answer","category":"page"},{"location":"API/Continuous Time/convergence/","page":"Convergence of Generators","title":"Convergence of Generators","text":"log(perron_frobenius(markov_chain)) / dt","category":"page"},{"location":"API/Continuous Time/convergence/","page":"Convergence of Generators","title":"Convergence of Generators","text":"Let us now automate the process of checking convergence as function of fixed timestep size. We generate a Markov chain of increasing size and compute the empirical transition matrix. We then verify that the empirical transition matrix converges to the exact transition operator. We use the function norm from the LinearAlgebra package to compute the norm of the difference between the empirical and exact transition matrices. We use the difference between the matrices divided by the norm of the exact matrix to get a relative error. At small timesteps the transfer operator converges to the identity matrix, hence we divide the error by a factor of dt in order to make a fair comparison to the relative error of the generator matrix. The takeaway message is that the error of the generator is bounded by both the timestep size and the available number of independent samples in the data. Here is the code to verify this statement","category":"page"},{"location":"API/Continuous Time/convergence/","page":"Convergence of Generators","title":"Convergence of Generators","text":"using LinearAlgebra: norm\nprintln(\"Transfer Operator Convergence\")\nfor dt in [1.0, 0.1, 0.01, 0.001]\n    ℳ_exact_local = exp(Q_exact * dt)\n    println(\"For a timestep of $dt\")\n    for i in 2:2:6\n        n = 10^i\n        markov_chain_local = generate(ℳ_exact_local, n)\n        number_of_states = 2\n        ℳ_empirical_local = perron_frobenius(markov_chain_local, number_of_states)\n        empirical_error = norm(ℳ_empirical_local - ℳ_exact_local) / norm(ℳ_exact_local) / dt\n        println(\"A chain of size 10^$i yields a relative empirical error of $(empirical_error)\")\n    end\n    println(\"---------------------------\")\nend\n\nprintln(\"---------------------------\")\nprintln(\"Generator Convergence\")\nfor dt in [1.0, 0.1, 0.01, 0.001]\n    ℳ_exact_local = exp(Q_exact * dt)\n    println(\"For a timestep of $dt\")\n    for i in 2:2:6\n        n = 10^i\n        markov_chain_local = generate(ℳ_exact_local, n)\n        number_of_states = 2\n        Q_empirical_local = generator(markov_chain_local, number_of_states; dt = dt)\n        empirical_error = norm(Q_empirical_local - Q_exact) / norm(Q_exact)\n        println(\"A chain of size 10^$i yields a relative empirical error of $(empirical_error)\")\n    end\n    println(\"---------------------------\")\nend","category":"page"},{"location":"API/Continuous Time/convergence/","page":"Convergence of Generators","title":"Convergence of Generators","text":"In particular, for the convergence of the generator, we see that the error is roughly on the order of the timestep size, except for the last case. A heuristic explanation for this behavior is as follows. If we think of each entry of the matrix as a random variable then the convergence to the expected value (the exact entry of the matrix) is inversely proportional to the square root of the number of independent samples. As one decreases the timestep size, the number of independent samples decrease since the number of timesteps is fixed, that is to say we are looking at the simulation for an increasingly shorter amount of physical time. Roughly speaking one would expect the error to be ","category":"page"},{"location":"API/Continuous Time/convergence/","page":"Convergence of Generators","title":"Convergence of Generators","text":"error propto max left(dt frac1sqrtS  right)","category":"page"},{"location":"API/Continuous Time/convergence/","page":"Convergence of Generators","title":"Convergence of Generators","text":"where S is the number of independent samples. In the last case, since the largest decorrelation time of the markov chain is on the order of 1 time unit, we expect the number of independent samples in a physical time interval of 10^6  dt = 10^3 to be roughly on the order of 10^3  5, where 5 time units is taken as a decorrelation threshold for the markov chain. We see that the error is ","category":"page"},{"location":"API/Continuous Time/convergence/","page":"Convergence of Generators","title":"Convergence of Generators","text":"approximate_error = 1 / sqrt(10^3 / 5)","category":"page"},{"location":"API/Continuous Time/convergence/","page":"Convergence of Generators","title":"Convergence of Generators","text":"which is roughly the same order of magnitude as the final error.","category":"page"},{"location":"API/Continuous Time/convergence/","page":"Convergence of Generators","title":"Convergence of Generators","text":"We haven't discussed what happens as the number of states increases and the more nuanced behavior of both the generator matrix and transfer operator as the number of states increases. In general, the more states that one has the more data is needed to estimate the different entries of the matrix; however this need not always be the case, as there are some interesting exceptions to this rule. In particular if there is an underlying (or approximate) tensor product structure to the generator or transfer operator then the number of independent samples needed to estimate the entries of the matrix can be reduced. ","category":"page"},{"location":"API/Discrete Time/convergence/#sec:to_convergence","page":"Convergence of Transfer Operators","title":"Convergence of Transfer Operators","text":"","category":"section"},{"location":"API/Discrete Time/convergence/","page":"Convergence of Transfer Operators","title":"Convergence of Transfer Operators","text":"In this section we show how to verify convergence of transfer operators. We use the following example: ","category":"page"},{"location":"API/Discrete Time/convergence/","page":"Convergence of Transfer Operators","title":"Convergence of Transfer Operators","text":"Given the exact transfer operator","category":"page"},{"location":"API/Discrete Time/convergence/","page":"Convergence of Transfer Operators","title":"Convergence of Transfer Operators","text":"ℳ_exact = [0.6 0.3; 0.4 0.7]\nℳ_exact","category":"page"},{"location":"API/Discrete Time/convergence/","page":"Convergence of Transfer Operators","title":"Convergence of Transfer Operators","text":"We generate a Markov chains of increasing size and compute the empirical transition matrix. We then verify that the empirical transition matrix converges to the exact transition operator. Let us first generate a Markov chain of size 100.","category":"page"},{"location":"API/Discrete Time/convergence/","page":"Convergence of Transfer Operators","title":"Convergence of Transfer Operators","text":"using MarkovChainHammer.Trajectory: generate\nusing Random #hide\nRandom.seed!(1234) #hide\nmarkov_chain = generate(ℳ_exact, 100); \nnothing; # hide","category":"page"},{"location":"API/Discrete Time/convergence/","page":"Convergence of Transfer Operators","title":"Convergence of Transfer Operators","text":"and then compute the empirical operator","category":"page"},{"location":"API/Discrete Time/convergence/","page":"Convergence of Transfer Operators","title":"Convergence of Transfer Operators","text":"using MarkovChainHammer.TransitionMatrix: perron_frobenius\nℳ_empirical = perron_frobenius(markov_chain)\nℳ_empirical","category":"page"},{"location":"API/Discrete Time/convergence/","page":"Convergence of Transfer Operators","title":"Convergence of Transfer Operators","text":"We see that the empirical transition matrix is close to the exact transition matrix. Let us now generate a Markov chain of size 10000 and compute the empirical transition matrix.","category":"page"},{"location":"API/Discrete Time/convergence/","page":"Convergence of Transfer Operators","title":"Convergence of Transfer Operators","text":"markov_chain = generate(ℳ_exact, 10000);\nℳ_empirical = perron_frobenius(markov_chain)\nℳ_empirical","category":"page"},{"location":"API/Discrete Time/convergence/","page":"Convergence of Transfer Operators","title":"Convergence of Transfer Operators","text":"We see that the empirical transition matrix is closer to the exact transition matrix. ","category":"page"},{"location":"API/Discrete Time/convergence/","page":"Convergence of Transfer Operators","title":"Convergence of Transfer Operators","text":"Let us now automate the process of checking convergence. We generate a Markov chain of increasing size and compute the empirical transition matrix. We then verify that the empirical transition matrix converges to the exact transition operator. We use the function norm from the LinearAlgebra package to compute the norm of the difference between the empirical and exact transition matrices.","category":"page"},{"location":"API/Discrete Time/convergence/","page":"Convergence of Transfer Operators","title":"Convergence of Transfer Operators","text":"using LinearAlgebra: norm\nfor i in 2:2:6\n    n = 10^i\n    markov_chain_local = generate(ℳ_exact, n)\n    ℳ_empirical_local = perron_frobenius(markov_chain_local)\n    empirical_error = norm(ℳ_empirical_local - ℳ_exact)\n    println(\"A chain of size 10^$i yields an empirical error of $(empirical_error)\")\nend","category":"page"},{"location":"API/Discrete Time/convergence/","page":"Convergence of Transfer Operators","title":"Convergence of Transfer Operators","text":"We see that the error in the empirical estimate decreases as the chain size increases.","category":"page"},{"location":"API/Discrete Time/convergence/","page":"Convergence of Transfer Operators","title":"Convergence of Transfer Operators","text":"Here we used knowledge of the exact operator to show that the empirical operator converges. If we only have the data, as is often the case in practice, then we cannot know if the empirical operator is sufficiently well-estimated; however, sometimes we know particular abstract properties of the Markov chain which imply theoretical gaurantees on the convergence of the empirical operator in the limit of infinite data. On the other end, given a finite time-series, we can view the operator as a compression algorithm for the stochastic process in which case we only look for data-consistency.  ","category":"page"},{"location":"Modules/transition_matrix/#sec:transition_matrix","page":"TransitionMatrix","title":"Transition Matrix","text":"","category":"section"},{"location":"Modules/transition_matrix/","page":"TransitionMatrix","title":"TransitionMatrix","text":"This module creates several convenience functions for construction transfer operators and generators from Markov chains. The two most useful functions are  the generator function and the perron_frobenius functions.","category":"page"},{"location":"API/Discrete Time/transfer_operators/#sec:transfer_operators","page":"Transfer Operators and Markov Chains","title":"Transfer Operators and Markov Chains","text":"","category":"section"},{"location":"API/Discrete Time/transfer_operators/","page":"Transfer Operators and Markov Chains","title":"Transfer Operators and Markov Chains","text":"Markov chains are a stochastic process whose future state only depends on the current state. In this repository we only consider Markov chains with a finite state space, thus the transition probabilities are characterized by matrix. In this section we will see how to generate a Markov chain from a known transition matrix. The transition matrix is also known as the transfer operator or the Perron-Frobenius matrix / operator. It can also be viewed as the adjoint of the Koopman operator.","category":"page"},{"location":"API/Discrete Time/transfer_operators/","page":"Transfer Operators and Markov Chains","title":"Transfer Operators and Markov Chains","text":"The convention taken in this repository is that all transfer operators are column stochastic. For example, the following 2 times 2  column stochastic matrix characterizes a Markov process made up of 2 discrete states,","category":"page"},{"location":"API/Discrete Time/transfer_operators/","page":"Transfer Operators and Markov Chains","title":"Transfer Operators and Markov Chains","text":"beginaligned\n    mathcalM =\n    beginbmatrix\n    06  03 \n    04  07\n    endbmatrix\nendaligned","category":"page"},{"location":"API/Discrete Time/transfer_operators/","page":"Transfer Operators and Markov Chains","title":"Transfer Operators and Markov Chains","text":"The first column, c_1,","category":"page"},{"location":"API/Discrete Time/transfer_operators/","page":"Transfer Operators and Markov Chains","title":"Transfer Operators and Markov Chains","text":"beginaligned\n    c_1 =\n    beginbmatrix\n    06 \n    04 \n    endbmatrix\nendaligned","category":"page"},{"location":"API/Discrete Time/transfer_operators/","page":"Transfer Operators and Markov Chains","title":"Transfer Operators and Markov Chains","text":"gives information about what happens to a link in the chain that is state 1. The probability, mathcalM_11, of staying in state 1 given that we are in state 1 is mathcalM_11 = 06 and the probability of going to state 2 given that we are in state 1 is mathcalM_21 = 04. Similarly, the second column, c_2,","category":"page"},{"location":"API/Discrete Time/transfer_operators/","page":"Transfer Operators and Markov Chains","title":"Transfer Operators and Markov Chains","text":"beginaligned\n    c_2 =\n    beginbmatrix\n    03 \n    07\n    endbmatrix\nendaligned","category":"page"},{"location":"API/Discrete Time/transfer_operators/","page":"Transfer Operators and Markov Chains","title":"Transfer Operators and Markov Chains","text":"gives information about what happens to a link in the chain that is state 2. The probability, mathcalM_22, of staying in state 2 given that we are in state 2 is mathcalM_22 = 07 and the probability of going to state 1 given that we are in state 2 is mathcalM_12 = 03. ","category":"page"},{"location":"API/Discrete Time/transfer_operators/","page":"Transfer Operators and Markov Chains","title":"Transfer Operators and Markov Chains","text":"A sample markov chain is constructed from a transfer operator using generate function from the MarkovChainHammer.Trajectory module. The following code snippet constructs 10 steps of a Markov chain from the transfer operator mathcalM above.","category":"page"},{"location":"API/Discrete Time/transfer_operators/","page":"Transfer Operators and Markov Chains","title":"Transfer Operators and Markov Chains","text":"using MarkovChainHammer.Trajectory: generate\nusing Random #hide\nRandom.seed!(1234) #hide\nℳ = [0.6 0.3; 0.4 0.7]\nsteps = 10\nmarkov_chain = generate(ℳ, steps)'","category":"page"},{"location":"API/Discrete Time/transfer_operators/","page":"Transfer Operators and Markov Chains","title":"Transfer Operators and Markov Chains","text":"The sequence of numbers are the Markov chain. A number 1 indicates that the chain is in state 1 and a number 2 indicates that the chain is in state 2 and the sequence of numbers is the sequence of states that the chain has visited. The Markov chain is but one possible realization of the stochastic process. If we were to run the generate function again, we would get a different realization of the Markov chain,","category":"page"},{"location":"API/Discrete Time/transfer_operators/","page":"Transfer Operators and Markov Chains","title":"Transfer Operators and Markov Chains","text":"markov_chain = generate(ℳ, steps)'","category":"page"},{"location":"API/Discrete Time/transfer_operators/","page":"Transfer Operators and Markov Chains","title":"Transfer Operators and Markov Chains","text":"If the number of steps is not specified, then the code attempts to generated a chain with roughly 10,000 independent samples of the process based on a decorrelation time threshold,  ","category":"page"},{"location":"API/Discrete Time/transfer_operators/","page":"Transfer Operators and Markov Chains","title":"Transfer Operators and Markov Chains","text":"markov_chain = generate(ℳ)'","category":"page"},{"location":"API/Continuous Time/generators/#sec:generators","page":"Generators","title":"Generators","text":"","category":"section"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"In this section we discuss continuous time markov processes and methods for generating Markov chains from them. They are similar to a discrete time Markov chain, but with a notion of time built into their construction. The idea is to break up the time interval into a sequence of discrete time steps and then construct a discrete time Markov chain from the continuous time Markov process.","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"We start by building from the knowledge of the discrete time Markov chain and transfer operators. As mentioned before the columns of the transfer operator give information on where to go at a subsequent discrete step. But now we want to shift and develop a method that is consistent with the notion of continuous time. Thus the first thing we need to think about is, \"How far do we go in time?\" and then secondly \"How do we make this consistent with the notion of a Markov process?\". ","category":"page"},{"location":"API/Continuous Time/generators/#Motivation","page":"Generators","title":"Motivation","text":"","category":"section"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"To motivate the use of a generator, we reexamine the transfer operator","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"ℳ = [0.6 0.3; 0.4 0.7]\nℳ","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"The transfer operator determines the probability of state j (here j = 1 or 2) to move to state i in one step. But suppose that we want to know the probability of moving from one state to another in two steps. For example, suppose that we are in state s_0 = 1 at time 0, then","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"s₀ = [1, 0]","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"Thus the probability of being in state 1 or state 2 at time 1 is given by matrix multiplication with the state ","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"s₁ = ℳ * s₀","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"Now we would find that 60% of our ensembles would be in state 1 after one step and 40% would be in state 2 after one step. But now suppose that we want to figure out how many of our ensembles of states would be in state 1 or state 2 after another step. We simply apply the operator again ","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"s₂ = ℳ * s₁","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"To get that 48% of our states ended up in state 1 and 52% of our states ended up in state 2. In total, if we want to just jump straight from our initial state s_0 to state s_2, we can just combine the two steps to get ","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"ℳ * ℳ * s₀","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"Thus we see if we want to move one step, we just multiply s_0 by ℳ, if we want to move two steps we multiply s_0 by, mathcalℳ^2. In general, if we want to move n-steps, where n is a natural number, then we mulitply by mathcalℳ^n. If we want to move \"0\" steps, we can use the convention that mathcalℳ^0 = mathbbI where mathbbI is the identity matrix.","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"But now suppose that we don't want to compute at just integer steps, we want to compute what \"happens in between\", that is to say, raise to a non-integer power. One way to define this for matrices is to make use of the identity","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"mathcalM^n = expn log(mathcalM)","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"where the log and exp functions are the matrix logarithm and matrix exponential. For example, the matrix logarithm of mathcalM is","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"logℳ = log(ℳ)\nlogℳ = real.(log(ℳ)) #hide","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"and we can check ","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"exp(logℳ) - ℳ\nreal.(exp(real.(log(ℳ))) - ℳ) # hide","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"We see that the mathematical relation holds to machine precision.","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"We can now check the formula for n=2","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"n = 2\nexp(n * log(ℳ)) - ℳ^n\nreal.(exp(n * log(ℳ)) - ℳ^n) # hide","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"which we again see holds to machine precision.","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"And finally, we can see what happens if we take non-integer steps","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"n = 1.5\nℳhalf = exp(n * log(ℳ)) ","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"and check to see taking two steps of size 1.5 is the same as taking one step of size 3. We square the matrix corresponding to a step size of 1.5 and check that it is the same as the matrix corresponding to a step size of 3. We take the difference of the two calculations","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"ℳhalf^2 - ℳ^3","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"to see that the entries are the same to machine precision.","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"This brings us to the point we were can finally introduce the generator. Presently, the generator is the matrix logarithm of the transfer operator ","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"Q = log(ℳ)\nQ = real.(log(ℳ)) # hide","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"However, we have actually presented the relation backwards! The transfer operator for a time tau in the future is the matrix exponential of the generator Q","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"P(τ) = exp(Q * τ)\nnothing # hide","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"In order for the formula to hold for all times tau, stricter requirements must be imposed on the generator. In order for P(tau) to be a probability for all times tau, we require ","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"The sum of the columns of Q must be zero \nThe off diagonal terms of Q must be greater than or equal to zero","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"These two requirements can be derived by taking tau to be an infinitely small timestep, which we denote by dt, from whence we see ","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"P(dt) = mathbbI + Q  dt","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"where mathbbI is the identity matrix. Since the sum of the columns on the left hand side must be one and the sum of the columns of the identity matrix is one, we see that the only option is for the sum of the columns of Q to be zero for the identity to hold. The positivity of the off-diagonal terms of the transfer operator implies that the off-diagonal terms of the generator matrix, Q must be positive since the formula holds for every entry of the matrix and the identity matrix only modifies the diagonal terms. In fact we can say a bit more. Since probabilities are bounded above by one, we can say that the diagonal terms of the generator matrix must be less than or equal to zero.","category":"page"},{"location":"API/Continuous Time/generators/#Using-the-generator-to-contruct-Markov-chains","page":"Generators","title":"Using the generator to contruct Markov chains","text":"","category":"section"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"We can now use the generator to construct Markov chains. The API in MarkovChainHammer.jl allows for two possibilites. The first is to construct the transfer operator from the generator and then directly use transfer operator as was done in the Transfer Operators and Markov Chains section. ","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"For example, defining a generator Q and transfer operator P(tau) as ","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"using Random #hide\nRandom.seed!(1234) #hide\nQ = [-1.0 2.0; 1.0 -2.0]\nP(τ) = exp(Q * τ)\nnothing #hide","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"We can define the tau = 1, transfer operator ","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"P1 = P(1.0)","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"and then use the generate function as before, ","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"using MarkovChainHammer.Trajectory: generate\nmarkov_chain = generate(P1, 10)'","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"The second possibility is to use the generator directly. This is done by defining a generator Q, choosing a step size dt, and then using the generate function with the generator ","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"n = 10; dt = 1.0;\nmarkov_chain = generate(Q, n; dt = dt)'","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"The above is a chain of length 10, whose time intervals correspond to steps of size dt = 10. The dt term is a keyword argument to the function and associated with a step size. Thus time \"time\" associated with the chain is, ","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"time = dt * collect(0:n-1)'","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"We can also generate a markov chain sequence of length n=100 with a step size dt = 01 and then use the generate function to generate a chain of length n with a step size dt. ","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"n = 100; dt = 0.1;\nmarkov_chain = generate(Q, n; dt = dt)'","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"where now the times associated with the process are ","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"time = dt * collect(0:n-1)'","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"The flexibility of choosing the step size corresponding to a time, and still having the resulting process be Markovian, is a powerful feature of the generator. Choosing an arbitrary dt but having the statistics remain the same over a physical timescale is what makes the resulting process a \"continuous time markov process\".","category":"page"},{"location":"API/Continuous Time/generators/#Generator-properties","page":"Generators","title":"Generator properties","text":"","category":"section"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"In the previous section we introduced the generator, but we did not delve into details about it's properties or how to interpret the entries of the matrix. This subsection aims to rectify that. We start by interpreting the diagonal entries of the generator matrix and then we will move to interpret the off-diagonal entries. We will soon see that ","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"The diagonal entries contain information on how much time to spend in a state \nThe off-diagonal entries contain information on how to transition between states","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"We comment that the generator matrix has units of inverse time whereas the transfer operator is dimensionless. Throughout this section we will use the notation Q to denote the generator matrix and Q_ij to denote the entry in the ith row and jth column of the matrix.","category":"page"},{"location":"API/Continuous Time/generators/#Diagonal-entries","page":"Generators","title":"Diagonal entries","text":"","category":"section"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"The diagonal entries are used to compute the holding times associated with states of the markov process. The holding time is an exponentially distributed random variable with mean -frac1Q_ii. The mean is the inverse of the diagonal entry.","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"For example, the generator matrix ","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"Q = [-1 1 1; 1 -2 2; 0 1 -3]","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"has three states, 1 2 3. The holding time for state 1 is exponentially distributed with mean -frac1Q_11 = frac11 = 1. The holding time for state i = 2 is exponentially distributed with mean -frac1Q_22 = frac12. The holding time for state i = 3 is exponentially distributed with mean -frac1Q_33 = frac13. Thus the larger the number on the diagonal the less time it spends in that state.","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"We can draw a random sample from the holding time distribution using the rand function and the Exponential struct from the Distributions package. For example, to draw a random sample from the holding time distribution for state 1 we can use the following code","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"using Distributions\nτ₁ = Exponential(-1 / Q[1,1])\nrand(τ₁)","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"and if we want to draw another sample from the distribution, we simply call the function again, ","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"rand(τ₁)","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"and if we want to draw 10 realizations ","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"rand(τ₁, 10)'","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"and so forth.","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"To draw a random sample from the holding time distribution for state 2 we can use the following code","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"τ₂ = Exponential(-1 / Q[2,2])\nrand(τ₂)","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"and to draw a random sample from the holding time distribution for state 3 we can use the following code","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"τ₃ = Exponential(-1 / Q[3,3])\nrand(τ₃)","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"Thus we have seen how to remain in a state for a random amount of time. The next step is to move from one state to another.","category":"page"},{"location":"API/Continuous Time/generators/#Off-diagonal-entries","page":"Generators","title":"Off-diagonal entries","text":"","category":"section"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"The diagonal entries told us how long to stay in a state. The off-diagonal entries tell us how to transition between states. For example, using the same 3 times 3 generator matrix from before","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"Q = [-1 1 1; 1 -2 2; 0 1 -3]","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"we now describe the transition process from one state to another. Suppose that we start in state 2. We see by examning the column ","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"Q[:,2]","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"That we spend an exponentially distributed random amount of time with mean 12 in state 2, then leave the state. Thus the question becomes, \"to which state do we go and with what probability?\". There are two possibilities since we have a 3 state system. We can leave to state 1 or state 3. The probability of leaving to state 1 is proportional to the Q_12 entry of the matrix and the probability of leaving to state 3 is proportional to the Q_32 entry. That is to say, we are equally likely to leave to state 1 or state 3. The normalization factor is the sum of the two entries. Thus the probability of leaving to state 1 is fracQ_12Q_12 + Q_32 = frac12 and the probability of leaving to state 3 is fracQ_32Q_12 + Q_32 = frac12. ","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"A similar story holds for the other states. For example, if we start in state 1, we see by examning the column ","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"Q[:, 1]","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"that we spend an exponentially distributed random amount of time with mean 1 in state 1, then leave the state. Thus the question becomes, \"to which state do we go and with what probability?\". There are two possibilities since we have a 3 state system. We can leave to state 2 or state 3. The probability of leaving to state 2 is proportional to the Q_21 entry of the matrix and the probability of leaving to state 3 is proportional to the Q_31 entry. Since Q_31 = 0 we are 100% likely to leave to state 2. Thus the probability of leaving to state 2 is fracQ_21Q_21 + Q_31 = 1 and the probability of leaving to state 3 is fracQ_31Q_21 + Q_31 = 0.","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"And finally if we start in state 3, we see by examning the column ","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"Q[:, 3]","category":"page"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"that we spend an exponentially distributed random amount of time with mean 13 in state 3, then leave the state. Thus the question becomes, \"to which state do we go and with what probability?\". There are two possibilities since we have a 3 state system. We can leave to state 1 or state 2. The probability of leaving to state 1 is proportional to the Q_13 entry of the matrix and the probability of leaving to state 2 is proportional to the Q_23 entry. Since Q_13 = 1 and Q_23 = 2 we are twice as likely to leave to state 2. Thus the probability of leaving to state 1 is fracQ_13Q_13 + Q_23 = 13 and the probability of leaving to state 2 is fracQ_23Q_13 + Q_23 = 23.","category":"page"},{"location":"API/Continuous Time/generators/#Final-Comments","page":"Generators","title":"Final Comments","text":"","category":"section"},{"location":"API/Continuous Time/generators/","page":"Generators","title":"Generators","text":"We have described two methods of simulating a continuous time markov chain. The first method is to construct a transfer operator and then sample at discrete times. The second method is to construct a generator and then sample at continuous times. The two methods are equivalent. The first method is better for working with evenly spaced times, but can suffer from sampling problems if a timestep is chosen \"too far in the future\" since any short time information is lost. The second method is more true to the continuum nature of a continuous time markov process but suffers from unevenly spaced times. ","category":"page"},{"location":"Modules/bayesian_matrix/#sec:bayesian_matrix","page":"BayesianMatrix","title":"Bayesian Matrix","text":"","category":"section"},{"location":"Modules/bayesian_matrix/","page":"BayesianMatrix","title":"BayesianMatrix","text":"This module contains structs and functions for manipulating matrices that account for the uncertainty of learning from data. The most useful object is the BayesianGenerator object which creates a particular kind of random matrix that is useful for Bayesian inference of constructing generators from data. ","category":"page"},{"location":"API/overview/#sec:api_overview","page":"Overview","title":"Overview","text":"","category":"section"},{"location":"API/overview/","page":"Overview","title":"Overview","text":"This repository gathers various convenience tools for analyzing and generating Markov Chains with a finite state space. The following subsections increase in conceptual complexity and are intended to be read in order.","category":"page"},{"location":"API/overview/#Discrete-time-Markov-chains","page":"Overview","title":"Discrete time Markov chains","text":"","category":"section"},{"location":"API/overview/","page":"Overview","title":"Overview","text":"The following sections contain a review of Markov Chains and an introduction to functionality in the repository. ","category":"page"},{"location":"API/overview/","page":"Overview","title":"Overview","text":"Transfer Operators and Markov Chains: Generate a Markov Chain from a transfer operator\nData-driven Transfer Operators: Construct empirical transition matrices and distributions from a Markov Chain\nConvergence of Transfer Operators: Verify convergence of empirical transition matrices and distributions to the true transition operator","category":"page"},{"location":"API/overview/#Continuous-time-Markov-chains","page":"Overview","title":"Continuous time Markov chains","text":"","category":"section"},{"location":"API/overview/","page":"Overview","title":"Overview","text":"The following sections contain more advanced mathematical concepts using continuous time Markov processes ","category":"page"},{"location":"API/overview/","page":"Overview","title":"Overview","text":"Generators and Markov Chains: Create a Markov chain from a generator matrix\nData-driven Generator: Construct empirical generators from a Markov Chain\nConvergence of Generators: Verify convergence of empirical generators to the true generator","category":"page"},{"location":"API/overview/#Uncertainty-Quantification","page":"Overview","title":"Uncertainty Quantification","text":"","category":"section"},{"location":"API/overview/","page":"Overview","title":"Overview","text":"The following sections introduce uncertainty quantification for the estimate of Generators from finite data","category":"page"},{"location":"API/overview/","page":"Overview","title":"Overview","text":"Bayesian Empirical Generator: Estimate the uncertainty of the entries in the empirical generator from finite data\nConstructing Prior Distributions: Construct and use prior distributions for the entries in the empirical generator\nSampling from the Bayesian Generator: Sample from the Bayesian empirical generator to propagate uncertainties","category":"page"},{"location":"API/Discrete Time/empirical_transfer_operators/#sec:empirical_transfer_operators","page":"Data-driven Transfer Operators","title":"Data-driven Transfer Operators","text":"","category":"section"},{"location":"API/Discrete Time/empirical_transfer_operators/","page":"Data-driven Transfer Operators","title":"Data-driven Transfer Operators","text":"Previously, we have seen how to construct a transfer operator from a Markov chain. In this section, we will see how to construct a transfer operator from data. This is useful when we don't know the underlying transfer operator.","category":"page"},{"location":"API/Discrete Time/empirical_transfer_operators/","page":"Data-driven Transfer Operators","title":"Data-driven Transfer Operators","text":"For example, suppose that we have the Markov chain","category":"page"},{"location":"API/Discrete Time/empirical_transfer_operators/","page":"Data-driven Transfer Operators","title":"Data-driven Transfer Operators","text":"markov_chain = [1 1 2 2 2 1]","category":"page"},{"location":"API/Discrete Time/empirical_transfer_operators/","page":"Data-driven Transfer Operators","title":"Data-driven Transfer Operators","text":"and we want to estimate the transfer operator from this data. We can do this by using the function perron_frobenius which is imported from the MarkovChainHammer.TransitionMatrix module. This function takes a Markov chain as input and returns the empirical transition matrix of the Markov chain.","category":"page"},{"location":"API/Discrete Time/empirical_transfer_operators/","page":"Data-driven Transfer Operators","title":"Data-driven Transfer Operators","text":"using MarkovChainHammer.TransitionMatrix: perron_frobenius\nP = perron_frobenius(markov_chain)\nP","category":"page"},{"location":"API/Discrete Time/empirical_transfer_operators/","page":"Data-driven Transfer Operators","title":"Data-driven Transfer Operators","text":"This matrix is constructed by counting the number of times that the chain transitions from one state to another and dividing by the total number of transitions. For example, the entry P[1, 1] is the number of times that the chain transitions from state 1 to state 1 divided by the total number of transitions away from state 1. In this case, the chain transitions from state 1 to state 1, a total of 1 time. Furthermore, the chain transitions from state 1  to state 2 a total of 1 time. Thus the total number of transitions is 2 and the entries of the first column are P[1, 1] = 1/2 and P[2, 1] = 1/2.","category":"page"},{"location":"API/Discrete Time/empirical_transfer_operators/","page":"Data-driven Transfer Operators","title":"Data-driven Transfer Operators","text":"The second column of the matrix is constructed in the same way. The chain transitions from state 2 to state 1 a total of 1 time and from state 2 to state 2 a total of 2 times. Thus the entries of the second column are P[1, 2] = 1/3 and P[2, 2] = 2/3.","category":"page"},{"location":"#MarkovChainHammer.jl","page":"Home","title":"MarkovChainHammer.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for MarkovChainHammer.jl. There are several conventions in use throughout the repository: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"All transfer operators are represented as column stochastic matrices\nThe columns of the generator sum to zero\nAll markov chains are vectors of integers from 1 to n, where n is the number of states in the markov chain","category":"page"},{"location":"","page":"Home","title":"Home","text":"For an overview of Markov chains and the package application programming interface (API) see the API section. \nFor further details on each module within the repository see the Module Overview section. \nAnd for a more detailed explanation of the functions within each module, see the Function Index section.","category":"page"}]
}
